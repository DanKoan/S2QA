{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2e33dced-e587-4397-81b3-d6606aa1738a",
   "metadata": {},
   "source": [
    "# S2QA with Ollama - Llama 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5863dde9-84a0-4c33-ad52-cc767442f63f",
   "metadata": {},
   "source": [
    "## Setup\n",
    "First, follow the [readme](https://github.com/jmorganca/ollama#building) to set up and run a local Ollama instance.\n",
    "\n",
    "This demo is running -\n",
    "```bash\n",
    "./ollama run llama2:13b-chat\n",
    "```\n",
    "\n",
    "When the Ollama app is running on your local machine:\n",
    "- All of your local models are automatically served on localhost:11434\n",
    "- Select your model when setting llm = Ollama(..., model=\"<model family>:<version>\")\n",
    "- If you set llm = Ollama(..., model=\"<model family\") without a version it will simply look for latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a667d94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/shaurya/projects/S2QA/llama_index/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad297f19-998f-4485-aa2f-d67020058b7d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T02:07:09.825521Z",
     "start_time": "2023-09-12T02:07:08.193329Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.query_engine import CitationQueryEngine\n",
    "from llama_index import (\n",
    "    VectorStoreIndex,\n",
    "    ServiceContext,\n",
    ")\n",
    "from llama_index.response.notebook_utils import display_response\n",
    "from llama_hub.semanticscholar.base import SemanticScholarReader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "152ced37-9a42-47be-9a39-4218521f5e72",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T02:07:10.344425Z",
     "start_time": "2023-09-12T02:07:10.340295Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = Ollama(model=\"llama2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "203e6375",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2reader = SemanticScholarReader()\n",
    "\n",
    "# narrow down the search space\n",
    "query_space = \"biases in large language models\"\n",
    "\n",
    "# increase limit to get more documents\n",
    "documents = s2reader.load_data(query=query_space, limit=10)\n",
    "\n",
    "service_context = ServiceContext.from_defaults(\n",
    "    llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc490b06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**`Final Response:`** Certainly! Here's a markdown table summarizing the different types of biases in large language models based on the provided sources:\n",
       "\n",
       "| Bias Type | Description | Sources |\n",
       "| --- | --- | --- |\n",
       "| Data selection bias | Bias caused by the choice of texts that make up a training corpus. | Source 1 |\n",
       "| Social bias | Biases evidenced in the text generated by language models trained on such corpora, ranging from gender to age, from sexual orientation to ethnicity, and from religion to culture. | Source 1, Source 2 |\n",
       "| Gender bias | Bias towards certain genders. | Source 2 |\n",
       "| Unintended consequences of biased model outputs | Ethical concerns arising from the unintended consequences of biased model outputs. | Source 3 |\n",
       "| Mitigating biases | Approaches to identify, quantify, and mitigate biases in language models. | Source 3 |\n",
       "\n",
       "Here's a brief explanation for each bias type:\n",
       "\n",
       "* Data selection bias: This occurs when the training data used to train large language models is not representative of the population or domain the model is intended to serve. For example, if a language model is trained on a dataset that contains mostly male names, it may have difficulty generating gender-neutral text.\n",
       "* Social bias: Large language models can learn biases from the data they are trained on, which can result in generated text that reflects these biases. For instance, a language model trained on a dataset that contains predominantly male authors may generate more masculine than feminine words.\n",
       "* Gender bias: As mentioned in Source 2, recent studies have shown that language models can learn to be biased towards certain genders. This can result in generated text that reinforces gender stereotypes or discrimination.\n",
       "* Unintended consequences of biased model outputs: Biases in large language models can lead to unintended consequences, such as perpetuating harmful stereotypes or contributing to social inequalities. For example, a language model trained on a dataset that contains offensive language may generate offensive text even if it is not intended to do so.\n",
       "* Mitigating biases: There are several approaches to identify, quantify, and mitigate biases in large language models, such as using diverse and representative training data, adjusting model parameters, or incorporating human feedback. Source 3 provides a comprehensive overview of these approaches.\n",
       "\n",
       "I hope this helps! Let me know if you have any further questions."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**`Source Node 1/3`**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** c6bcdf65-c293-450c-91cb-ab352a3fa773<br>**Similarity:** 0.8526282063593319<br>**Text:** Source 1:\n",
       "Biases in Large Language Models: Origins, Inventory, and Discussion In this article, we...<br>**Metadata:** {'title': 'Biases in Large Language Models: Origins, Inventory, and Discussion', 'venue': 'ACM Journal of Data and Information Quality', 'year': 2023, 'paperId': '6d0656d9bb60a2bea50c4b894fbcc5d1e32134e7', 'citationCount': 4, 'openAccessPdf': 'https://dl.acm.org/doi/pdf/10.1145/3597307', 'authors': ['Roberto Navigli', 'Simone Conia', 'Bj√∂rn Ross'], 'externalIds': {'DBLP': 'journals/jdiq/NavigliCR23', 'DOI': '10.1145/3597307', 'CorpusId': 258688053}}<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**`Source Node 2/3`**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 3ce61a64-9270-4b45-bf40-90e83ac729cb<br>**Similarity:** 0.8406245995128746<br>**Text:** Source 2:\n",
       "Disclosing the Biases in Large Language Models via Reward Based Interrogation The succe...<br>**Metadata:** {'title': 'Disclosing the Biases in Large Language Models via Reward Based Interrogation', 'venue': '', 'year': 2022, 'paperId': '8be25af7560907713ad9c787b664224edfd35505', 'citationCount': 0, 'openAccessPdf': None, 'authors': ['Ezgi Korkmaz'], 'externalIds': {'CorpusId': 253764622}}<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**`Source Node 3/3`**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 10b98fce-ed29-49df-b3b1-485dd1d84972<br>**Similarity:** 0.8333128382605138<br>**Text:** Source 3:\n",
       "Should ChatGPT be Biased? Challenges and Risks of Bias in Large Language Models As the ...<br>**Metadata:** {'title': 'Should ChatGPT be Biased? Challenges and Risks of Bias in Large Language Models', 'venue': 'arXiv.org', 'year': 2023, 'paperId': '16d83e930a4dab2d49f5d276838ddce79df3f787', 'citationCount': 31, 'openAccessPdf': None, 'authors': ['Emilio Ferrara'], 'externalIds': {'DBLP': 'journals/corr/abs-2304-03738', 'ArXiv': '2304.03738', 'DOI': '10.48550/arXiv.2304.03738', 'CorpusId': 258041203}}<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = VectorStoreIndex.from_documents(documents, service_context=service_context)\n",
    "\n",
    "query_engine = CitationQueryEngine.from_args(\n",
    "    index,\n",
    "    similarity_top_k=3,\n",
    "    citation_chunk_size=512,\n",
    ")\n",
    "\n",
    "# query the index\n",
    "query_string = \"explain all the biases in large language models in a markdown table\"\n",
    "# query the citation query engine\n",
    "response = query_engine.query(query_string)\n",
    "display_response(response, show_source=True, source_length=100, show_source_metadata=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957139a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
