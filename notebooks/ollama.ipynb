{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2e33dced-e587-4397-81b3-d6606aa1738a",
   "metadata": {},
   "source": [
    "# S2QA with Ollama - Llama 2\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5863dde9-84a0-4c33-ad52-cc767442f63f",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, follow the [readme](https://github.com/jmorganca/ollama#building) to set up and run a local Ollama instance.\n",
    "\n",
    "This demo is running -\n",
    "\n",
    "```bash\n",
    "./ollama run llama2:13b-chat\n",
    "```\n",
    "\n",
    "When the Ollama app is running on your local machine:\n",
    "\n",
    "- All of your local models are automatically served on localhost:11434\n",
    "- Select your model when setting llm = Ollama(..., model=\"<model family>:<version>\")\n",
    "- If you set llm = Ollama(..., model=\"<model family\") without a version it will simply look for latest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad297f19-998f-4485-aa2f-d67020058b7d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T02:07:09.825521Z",
     "start_time": "2023-09-12T02:07:08.193329Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.query_engine import CitationQueryEngine\n",
    "from llama_index import (\n",
    "    VectorStoreIndex,\n",
    "    ServiceContext,\n",
    ")\n",
    "from llama_index.response.notebook_utils import display_response\n",
    "from llama_hub.semanticscholar.base import SemanticScholarReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "152ced37-9a42-47be-9a39-4218521f5e72",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T02:07:10.344425Z",
     "start_time": "2023-09-12T02:07:10.340295Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**`Final Response:`** Sure! Here's a markdown table summarizing the biases in large language models discussed in the provided sources:\n",
       "\n",
       "| Bias | Source | Description |\n",
       "| --- | --- | --- |\n",
       "| Data selection bias | Source 1, 2 | Bias caused by the choice of texts that make up a training corpus. |\n",
       "| Social bias | Source 1, 2 | Bias in the text generated by language models trained on such corpora, ranging from gender to age, from sexual orientation to ethnicity, and from religion to culture. |\n",
       "| Unintentional consequences of biased model outputs | Source 2 | Arising from the nature of training data, model specifications, algorithmic constraints, product design, and policy decisions. |\n",
       "| Ethical concerns | Source 2 | Bias can lead to unethical or harmful outcomes, such as perpetuating stereotypes or discrimination. |\n",
       "| Opportunities to mitigate biases | Source 3 | Identifying qualitative categories of erroneous behavior beyond identifying individual errors, drawing inspiration from human cognitive biases. |\n",
       "\n",
       "Please note that this table is not an exhaustive list of all possible biases in large language models, but rather a summary of the biases discussed in the provided sources."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**`Source Node 1/3`**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** cd65f0c1-5086-4473-ae53-1dc74636759d<br>**Similarity:** 0.8526345658029143<br>**Text:** Source 1:\n",
       "Biases in Large Language Models: Origins, Inventory, and Discussion In this article, we...<br>**Metadata:** {'title': 'Biases in Large Language Models: Origins, Inventory, and Discussion', 'venue': 'ACM Journal of Data and Information Quality', 'year': 2023, 'paperId': '6d0656d9bb60a2bea50c4b894fbcc5d1e32134e7', 'citationCount': 4, 'openAccessPdf': 'https://dl.acm.org/doi/pdf/10.1145/3597307', 'authors': ['Roberto Navigli', 'Simone Conia', 'Bj√∂rn Ross'], 'externalIds': {'DBLP': 'journals/jdiq/NavigliCR23', 'DOI': '10.1145/3597307', 'CorpusId': 258688053}}<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**`Source Node 2/3`**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 9d3b8013-7109-4653-8cab-afd1fa92fa38<br>**Similarity:** 0.833325174947303<br>**Text:** Source 2:\n",
       "Should ChatGPT be Biased? Challenges and Risks of Bias in Large Language Models As the ...<br>**Metadata:** {'title': 'Should ChatGPT be Biased? Challenges and Risks of Bias in Large Language Models', 'venue': 'arXiv.org', 'year': 2023, 'paperId': '16d83e930a4dab2d49f5d276838ddce79df3f787', 'citationCount': 31, 'openAccessPdf': None, 'authors': ['Emilio Ferrara'], 'externalIds': {'DBLP': 'journals/corr/abs-2304-03738', 'ArXiv': '2304.03738', 'DOI': '10.48550/arXiv.2304.03738', 'CorpusId': 258041203}}<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**`Source Node 3/3`**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** b9a14e40-14ed-476b-a89c-6b88696c2168<br>**Similarity:** 0.8317752061345524<br>**Text:** Source 3:\n",
       "Capturing Failures of Large Language Models via Human Cognitive Biases Large language m...<br>**Metadata:** {'title': 'Capturing Failures of Large Language Models via Human Cognitive Biases', 'venue': 'Neural Information Processing Systems', 'year': 2022, 'paperId': '76f023c3a819fc58989a064a1b50825b11fce95d', 'citationCount': 29, 'openAccessPdf': None, 'authors': ['Erik Jones', 'J. Steinhardt'], 'externalIds': {'DBLP': 'journals/corr/abs-2202-12299', 'ArXiv': '2202.12299', 'CorpusId': 247084098}}<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "llm = Ollama(model=\"llama2\")\n",
    "\n",
    "s2reader = SemanticScholarReader()\n",
    "\n",
    "# narrow down the search space\n",
    "query_space = \"biases in large language models\"\n",
    "\n",
    "# increase limit to get more documents\n",
    "documents = s2reader.load_data(query=query_space, limit=10)\n",
    "\n",
    "service_context = ServiceContext.from_defaults(llm=llm)\n",
    "index = VectorStoreIndex.from_documents(documents, service_context=service_context)\n",
    "\n",
    "query_engine = CitationQueryEngine.from_args(\n",
    "    index,\n",
    "    similarity_top_k=3,\n",
    "    citation_chunk_size=512,\n",
    ")\n",
    "\n",
    "# query the index\n",
    "query_string = \"explain all the biases in large language models in a markdown table\"\n",
    "# query the citation query engine\n",
    "response = query_engine.query(query_string)\n",
    "display_response(\n",
    "    response, show_source=True, source_length=100, show_source_metadata=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
